{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A link to the \"baby\" CORA dataset. Not used and should be the same as the included `.tsv` files from https://relational.fit.cvut.cz/dataset/CORA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!wget http://www.cs.umd.edu/~sen/lbc-proj/data/cora.tgz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The is the full CORA dataset version 1.0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-02-01 08:09:43--  http://people.cs.umass.edu/~mccallum/data/cora-classify.tar.gz\n",
      "Resolving people.cs.umass.edu (people.cs.umass.edu)... 128.119.240.99\n",
      "Connecting to people.cs.umass.edu (people.cs.umass.edu)|128.119.240.99|:80... connected.\n",
      "HTTP request sent, awaiting response... 301 Moved Permanently\n",
      "Location: https://people.cs.umass.edu/~mccallum/data/cora-classify.tar.gz [following]\n",
      "--2023-02-01 08:09:43--  https://people.cs.umass.edu/~mccallum/data/cora-classify.tar.gz\n",
      "Connecting to people.cs.umass.edu (people.cs.umass.edu)|128.119.240.99|:443... connected.\n",
      "HTTP request sent, awaiting response... 304 Not Modified\n",
      "File ‘cora-classify.tar.gz’ not modified on server. Omitting download.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "!wget -N http://people.cs.umass.edu/~mccallum/data/cora-classify.tar.gz\n",
    "!tar --skip-old-files -zxf cora-classify.tar.gz\n",
    "CORA_PATH = Path('cora')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process `papers`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find all of the reference fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Line number: 2\n",
      "URL: http:##dimacs.rutgers.edu#techps#1994#94-07.ps\n",
      "Author(s): M.R. Garey & D.S. Johnson,\n",
      "Title: Computers and Intractibility: A Guide to the Theory of NP-Completeness, W.H.\n",
      "Publisher: Freeman,\n",
      "Address: New York,\n",
      "Year: 1979.\n",
      "\n",
      "\n",
      "Line number: 16\n",
      "URL: http:##www.cs.wisc.edu#~fischer#ftp#pub#tech-reports#ncstrl.uwmadison#CS-TR-90-907#CS-TR-90-907.ps.Z\n",
      "Author(s): D. DeWitt, P. Futtersack, D. Maier, F. Velez,\n",
      "Title: \"A Study of Three Alternative Workstation-Server Architectures for Object-Oriented Database Systems\",\n",
      "Publisher: \n",
      "Address: Brisbane, Australia,\n",
      "Year: 1990.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "PAPERS_FILE = 'papers'\n",
    "\n",
    "filename = CORA_PATH / PAPERS_FILE\n",
    "\n",
    "with open(filename, 'r') as file:\n",
    "    for i, line in enumerate(file):\n",
    "        if i >= 2:\n",
    "            break\n",
    "        # process the line\n",
    "        parts = line.strip().split(\"\\t\")\n",
    "        print(\"Line number:\", parts[0])\n",
    "        print(\"URL:\", parts[1])\n",
    "        details = parts[2].split(\"]\")[1].strip().split(\"<\")[1:]\n",
    "        details = [x.split(\">\") for x in details]\n",
    "        details = {x[0]: x[1].strip() for x in details}\n",
    "        print(\"Author(s):\", details.get(\"author\", \"\"))\n",
    "        print(\"Title:\", details.get(\"title\", \"\"))\n",
    "        print(\"Publisher:\", details.get(\"publisher\", \"\"))\n",
    "        print(\"Address:\", details.get(\"address\", \"\"))\n",
    "        print(\"Year:\", details.get(\"year\", \"\"))\n",
    "        print(\"\\n\")\n",
    "        \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'month' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-dd2dafe06a46>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m         df = df.append({'number': number, 'url': url, 'reference': reference, \n\u001b[1;32m     28\u001b[0m                        \u001b[0;34m'author'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mauthor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'title'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'publisher'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mpublisher\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m                        'address': address, 'month': month, 'year': year}, ignore_index=True)\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;31m# Print the dataframe\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'month' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "reference_fields = ['author', 'title', 'booktitle', 'publisher', 'address', 'month', 'year']\n",
    "\n",
    "# Initialize an empty dataframe\n",
    "df = pd.DataFrame(columns=['number', 'url', 'reference', 'author', 'title', 'publisher', 'address', 'month', 'year'])\n",
    "\n",
    "# Open the file\n",
    "with open(filename, 'r') as file:\n",
    "    # Loop through each line in the file\n",
    "    for i, line in enumerate(file):\n",
    "        if i >= 2:\n",
    "            break\n",
    "        \n",
    "        parts = line.strip().split(\"\\t\")\n",
    "        number = parts[0]\n",
    "        url = parts[1]\n",
    "        reference = parts[2].split(\" \")[0]\n",
    "        \n",
    "        details = parts[2].split(\"]\")[1].strip().split(\"<\")[1:]\n",
    "        details = [x.split(\">\") for x in details]\n",
    "        details = {x[0]: x[1].strip() for x in details}\n",
    "        \n",
    "        \n",
    "        author = details.get(\"author\", \"\")\n",
    "        title = details.get(\"title\", \"\")\n",
    "        publisher = details.get(\"publisher\", \"\")\n",
    "        address = details.get(\"address\", \"\")\n",
    "        year = details.get(\"year\", \"\")\n",
    "        # Add the values to the dataframe\n",
    "        df = df.append({'number': number, 'url': url, 'reference': reference, \n",
    "                       'author': author, 'title': title, 'publisher': publisher, \n",
    "                       'address': address, 'month': month, 'year': year}, ignore_index=True)\n",
    "\n",
    "# Print the dataframe\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'month', 'author', 'title', 'journal', 'editor', 'type', 'pages', 'booktitle', 'note', 'address', 'volume', 'publisher', 'institution', 'year'}\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Open the file\n",
    "all_tags = set()\n",
    "\n",
    "with open(filename, 'r') as file:\n",
    "    # Loop through each line in the file\n",
    "    for i, line in enumerate(file):\n",
    "        if i >= 500000:\n",
    "            break\n",
    "        # Use a regular expression to find all tags in the line\n",
    "        tags = re.findall(r'</(.*?)>', line)\n",
    "        all_tags |= set(tags)\n",
    "        # Loop through each tag found\n",
    "\n",
    "print(all_tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-2c5079112ed8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mline_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\t'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;31m# Extract the tags from the line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mtags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'<'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'>'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mline_split\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'<'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0;31m# Print the list of tags\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Open the file\n",
    "with open(filename, 'r') as file:\n",
    "    # Loop through each line in the file\n",
    "    for i, line in enumerate(file):\n",
    "        if i >= 5:\n",
    "            break\n",
    "        # Split the line by tab\n",
    "        line_split = line.strip().split('\\t')\n",
    "        # Extract the tags from the line\n",
    "        tags = [x.split('<')[1].split('>')[0] for x in line_split[3].split('<')[1:]]\n",
    "        # Print the list of tags\n",
    "        print(tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tags = elements[2].split(' ')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[Gar]',\n",
       " '<author>',\n",
       " 'M.R.',\n",
       " 'Garey',\n",
       " '&',\n",
       " 'D.S.',\n",
       " 'Johnson,',\n",
       " '</author>',\n",
       " '<title>',\n",
       " 'Computers',\n",
       " 'and',\n",
       " 'Intractibility:',\n",
       " 'A',\n",
       " 'Guide',\n",
       " 'to',\n",
       " 'the',\n",
       " 'Theory',\n",
       " 'of',\n",
       " 'NP-Completeness,',\n",
       " 'W.H.',\n",
       " '</title>',\n",
       " '<publisher>',\n",
       " 'Freeman,',\n",
       " '</publisher>',\n",
       " '<address>',\n",
       " 'New',\n",
       " 'York,',\n",
       " '</address>',\n",
       " '<year>',\n",
       " '1979.',\n",
       " '</year>']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'M.R.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags[2].strip('<author>').strip('</author>')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'M.R.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tags[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "015e23f85a79d4e79affeb2338f9eb152133e1ce3e5ad44260681d5c7da21376"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
